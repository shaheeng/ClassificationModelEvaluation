{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Classification Model - Binary Classification using Adult dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict whether income exceeds $50K/yr based on census data. Also known as \"Adult\" dataset.  \n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Census+Income  \n",
    "Attribute Information:  \n",
    "Listing of attributes:   \n",
    "\n",
    ">50K, <=50K.   \n",
    "\n",
    "**age**: continuous.   \n",
    "**workclas**s: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.   \n",
    "**fnlwgt**: continuous.   \n",
    "**education**: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.   \n",
    "**education-num**: continuous.   \n",
    "**marital-status**: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.   \n",
    "**occupation**: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.   \n",
    "**relationship**: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.   \n",
    "**race**: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.   \n",
    "**sex**: Female, Male.   \n",
    "**capital-gain**: continuous.   \n",
    "**capital-loss**: continuous.   \n",
    "**hours-per-week**: continuous.   \n",
    "**native-country**: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hourspw</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hourspw  native_country  income  \n",
       "0          2174             0       40   United-States   <=50K  \n",
       "1             0             0       13   United-States   <=50K  \n",
       "2             0             0       40   United-States   <=50K  \n",
       "3             0             0       40   United-States   <=50K  \n",
       "4             0             0       40            Cuba   <=50K  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "col_names = ['age', 'workclass','fnlwgt','education','education_num','marital_status','occupation','relationship','race','sex','capital_gain','capital_loss','hourspw','native_country','income']\n",
    "income = pd.read_csv(url, header=None, names=col_names)\n",
    "#income = pd.read_csv(url, header=None, names=col_names, na_values=[' ?'])\n",
    "print(income.shape)\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration\n",
    "Print out the unique values of each column in this dataframe.   \n",
    "Check for missing values, incorrect entries.  \n",
    "  \n",
    "Check for redundant columns - If there is a feature that only contains one value, it does not provide any added value for any classifier. The best thing to do is to remove this feature.  \n",
    "\n",
    "#### Data Preparation\n",
    "Remove any rows (with .dropna() )   \n",
    "Apply one hot encoding (to transform categorical data into numerical data)   \n",
    "Standardize the data (with StandardScaler().fit_transform(X)).  \n",
    "Fixing outliers  \n",
    "One way to deal with missing data is mean imputation: If we know that the values for a measurement fall in a certain range, we can fill in empty values with the average of that measurement. \n",
    "Distribution of the different classes in both the training and the test set should be equal to the distribution in the actual dataset.   \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hourspw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30162.000000</td>\n",
       "      <td>3.016200e+04</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.437902</td>\n",
       "      <td>1.897938e+05</td>\n",
       "      <td>10.121312</td>\n",
       "      <td>1092.007858</td>\n",
       "      <td>88.372489</td>\n",
       "      <td>40.931238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.134665</td>\n",
       "      <td>1.056530e+05</td>\n",
       "      <td>2.549995</td>\n",
       "      <td>7406.346497</td>\n",
       "      <td>404.298370</td>\n",
       "      <td>11.979984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.176272e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.784250e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.376285e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education_num  capital_gain  capital_loss  \\\n",
       "count  30162.000000  3.016200e+04   30162.000000  30162.000000  30162.000000   \n",
       "mean      38.437902  1.897938e+05      10.121312   1092.007858     88.372489   \n",
       "std       13.134665  1.056530e+05       2.549995   7406.346497    404.298370   \n",
       "min       17.000000  1.376900e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.176272e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.784250e+05      10.000000      0.000000      0.000000   \n",
       "75%       47.000000  2.376285e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "            hourspw  \n",
       "count  30162.000000  \n",
       "mean      40.931238  \n",
       "std       11.979984  \n",
       "min        1.000000  \n",
       "25%       40.000000  \n",
       "50%       40.000000  \n",
       "75%       45.000000  \n",
       "max       99.000000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age #unique 72\n",
      "workclass #unique 7\n",
      "fnlwgt #unique 20263\n",
      "education #unique 16\n",
      "education_num #unique 16\n",
      "marital_status #unique 7\n",
      "occupation #unique 14\n",
      "relationship #unique 6\n",
      "race #unique 5\n",
      "sex #unique 2\n",
      "capital_gain #unique 118\n",
      "capital_loss #unique 90\n",
      "hourspw #unique 94\n",
      "native_country #unique 41\n",
      "income #unique 2\n"
     ]
    }
   ],
   "source": [
    "for col in income.columns.values:\n",
    "    #\n",
    "    print(col,'#unique',income[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age [39 50 38 53 28 37 49 52 31 42 30 23 32 40 34 25 43 54 35 59 56 19 20 45 22\n",
      " 48 21 24 57 44 41 29 18 47 46 36 79 27 67 33 76 17 55 61 70 64 71 68 66 51\n",
      " 58 26 60 90 75 65 77 62 63 80 72 74 69 73 81 78 88 82 83 84 85 86 87]\n",
      "age #unique 73\n",
      "workclass [' State-gov' ' Self-emp-not-inc' ' Private' ' Federal-gov' ' Local-gov'\n",
      " ' ?' ' Self-emp-inc' ' Without-pay' ' Never-worked']\n",
      "workclass #unique 9\n",
      "fnlwgt [ 77516  83311 215646 ...,  34066  84661 257302]\n",
      "fnlwgt #unique 21648\n",
      "education [' Bachelors' ' HS-grad' ' 11th' ' Masters' ' 9th' ' Some-college'\n",
      " ' Assoc-acdm' ' Assoc-voc' ' 7th-8th' ' Doctorate' ' Prof-school'\n",
      " ' 5th-6th' ' 10th' ' 1st-4th' ' Preschool' ' 12th']\n",
      "education #unique 16\n",
      "education_num [13  9  7 14  5 10 12 11  4 16 15  3  6  2  1  8]\n",
      "education_num #unique 16\n",
      "marital_status [' Never-married' ' Married-civ-spouse' ' Divorced'\n",
      " ' Married-spouse-absent' ' Separated' ' Married-AF-spouse' ' Widowed']\n",
      "marital_status #unique 7\n",
      "occupation [' Adm-clerical' ' Exec-managerial' ' Handlers-cleaners' ' Prof-specialty'\n",
      " ' Other-service' ' Sales' ' Craft-repair' ' Transport-moving'\n",
      " ' Farming-fishing' ' Machine-op-inspct' ' Tech-support' ' ?'\n",
      " ' Protective-serv' ' Armed-Forces' ' Priv-house-serv']\n",
      "occupation #unique 15\n",
      "relationship [' Not-in-family' ' Husband' ' Wife' ' Own-child' ' Unmarried'\n",
      " ' Other-relative']\n",
      "relationship #unique 6\n",
      "race [' White' ' Black' ' Asian-Pac-Islander' ' Amer-Indian-Eskimo' ' Other']\n",
      "race #unique 5\n",
      "sex [' Male' ' Female']\n",
      "sex #unique 2\n",
      "capital_gain [ 2174     0 14084  5178  5013  2407 14344 15024  7688 34095  4064  4386\n",
      "  7298  1409  3674  1055  3464  2050  2176   594 20051  6849  4101  1111\n",
      "  8614  3411  2597 25236  4650  9386  2463  3103 10605  2964  3325  2580\n",
      "  3471  4865 99999  6514  1471  2329  2105  2885 25124 10520  2202  2961\n",
      " 27828  6767  2228  1506 13550  2635  5556  4787  3781  3137  3818  3942\n",
      "   914   401  2829  2977  4934  2062  2354  5455 15020  1424  3273 22040\n",
      "  4416  3908 10566   991  4931  1086  7430  6497   114  7896  2346  3418\n",
      "  3432  2907  1151  2414  2290 15831 41310  4508  2538  3456  6418  1848\n",
      "  3887  5721  9562  1455  2036  1831 11678  2936  2993  7443  6360  1797\n",
      "  1173  4687  6723  2009  6097  2653  1639 18481  7978  2387  5060]\n",
      "capital_gain #unique 119\n",
      "capital_loss [   0 2042 1408 1902 1573 1887 1719 1762 1564 2179 1816 1980 1977 1876 1340\n",
      " 2206 1741 1485 2339 2415 1380 1721 2051 2377 1669 2352 1672  653 2392 1504\n",
      " 2001 1590 1651 1628 1848 1740 2002 1579 2258 1602  419 2547 2174 2205 1726\n",
      " 2444 1138 2238  625  213 1539  880 1668 1092 1594 3004 2231 1844  810 2824\n",
      " 2559 2057 1974  974 2149 1825 1735 1258 2129 2603 2282  323 4356 2246 1617\n",
      " 1648 2489 3770 1755 3683 2267 2080 2457  155 3900 2201 1944 2467 2163 2754\n",
      " 2472 1411]\n",
      "capital_loss #unique 92\n",
      "hourspw [40 13 16 45 50 80 30 35 60 20 52 44 15 25 38 43 55 48 58 32 70  2 22 56 41\n",
      " 28 36 24 46 42 12 65  1 10 34 75 98 33 54  8  6 64 19 18 72  5  9 47 37 21\n",
      " 26 14  4 59  7 99 53 39 62 57 78 90 66 11 49 84  3 17 68 27 85 31 51 77 63\n",
      " 23 87 88 73 89 97 94 29 96 67 82 86 91 81 76 92 61 74 95]\n",
      "hourspw #unique 94\n",
      "native_country [' United-States' ' Cuba' ' Jamaica' ' India' ' ?' ' Mexico' ' South'\n",
      " ' Puerto-Rico' ' Honduras' ' England' ' Canada' ' Germany' ' Iran'\n",
      " ' Philippines' ' Italy' ' Poland' ' Columbia' ' Cambodia' ' Thailand'\n",
      " ' Ecuador' ' Laos' ' Taiwan' ' Haiti' ' Portugal' ' Dominican-Republic'\n",
      " ' El-Salvador' ' France' ' Guatemala' ' China' ' Japan' ' Yugoslavia'\n",
      " ' Peru' ' Outlying-US(Guam-USVI-etc)' ' Scotland' ' Trinadad&Tobago'\n",
      " ' Greece' ' Nicaragua' ' Vietnam' ' Hong' ' Ireland' ' Hungary'\n",
      " ' Holand-Netherlands']\n",
      "native_country #unique 42\n",
      "income [' <=50K' ' >50K']\n",
      "income #unique 2\n"
     ]
    }
   ],
   "source": [
    "for col in income.columns.values:\n",
    "    print(col, income[col].unique())\n",
    "    print(col,'#unique',income[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace  ' ?' with None\n",
    "for col in income.columns.values:\n",
    "    income[col] = income[col].apply(lambda x: None if x == ' ?' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in income.columns.values:\n",
    "    print(col, income[col].unique())\n",
    "    print(col,'#unique',income[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "(30162, 15)\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with misisng values\n",
    "print(income.shape)\n",
    "income = income.dropna(axis=0, how='any')\n",
    "print(income.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding categorical data  \n",
    "\n",
    "Most classifier can only work with numerical data, and will raise an error when categorical values in the form of strings are used as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['income',\n",
       " 'sex',\n",
       " 'education',\n",
       " 'race',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'native_country',\n",
       " 'marital_status',\n",
       " 'workclass']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use dataframe._get_numeric_data() to get numeric columns and then find out categorical columns\n",
    "allcols = income.columns\n",
    "numeric_cols = income._get_numeric_data().columns\n",
    "categorical_cols = list(set(allcols) - set(numeric_cols))\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'fnlwgt', 'capital_gain', 'capital_loss', 'hourspw', 'education_num']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(numeric_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 15)\n",
      "(30162, 14)\n",
      "(30162, 104)\n"
     ]
    }
   ],
   "source": [
    "print(income.shape)\n",
    "income_ohe = income.drop('income', axis=1)\n",
    "print(income_ohe.shape)\n",
    "income_ohe = pd.get_dummies(income_ohe)\n",
    "print(income_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice how the dataset exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'fnlwgt' 'education_num' 'capital_gain' 'capital_loss' 'hourspw'\n",
      " 'workclass_ Federal-gov' 'workclass_ Local-gov' 'workclass_ Private'\n",
      " 'workclass_ Self-emp-inc' 'workclass_ Self-emp-not-inc'\n",
      " 'workclass_ State-gov' 'workclass_ Without-pay' 'education_ 10th'\n",
      " 'education_ 11th' 'education_ 12th' 'education_ 1st-4th'\n",
      " 'education_ 5th-6th' 'education_ 7th-8th' 'education_ 9th'\n",
      " 'education_ Assoc-acdm' 'education_ Assoc-voc' 'education_ Bachelors'\n",
      " 'education_ Doctorate' 'education_ HS-grad' 'education_ Masters'\n",
      " 'education_ Preschool' 'education_ Prof-school' 'education_ Some-college'\n",
      " 'marital_status_ Divorced' 'marital_status_ Married-AF-spouse'\n",
      " 'marital_status_ Married-civ-spouse'\n",
      " 'marital_status_ Married-spouse-absent' 'marital_status_ Never-married'\n",
      " 'marital_status_ Separated' 'marital_status_ Widowed'\n",
      " 'occupation_ Adm-clerical' 'occupation_ Armed-Forces'\n",
      " 'occupation_ Craft-repair' 'occupation_ Exec-managerial'\n",
      " 'occupation_ Farming-fishing' 'occupation_ Handlers-cleaners'\n",
      " 'occupation_ Machine-op-inspct' 'occupation_ Other-service'\n",
      " 'occupation_ Priv-house-serv' 'occupation_ Prof-specialty'\n",
      " 'occupation_ Protective-serv' 'occupation_ Sales'\n",
      " 'occupation_ Tech-support' 'occupation_ Transport-moving'\n",
      " 'relationship_ Husband' 'relationship_ Not-in-family'\n",
      " 'relationship_ Other-relative' 'relationship_ Own-child'\n",
      " 'relationship_ Unmarried' 'relationship_ Wife' 'race_ Amer-Indian-Eskimo'\n",
      " 'race_ Asian-Pac-Islander' 'race_ Black' 'race_ Other' 'race_ White'\n",
      " 'sex_ Female' 'sex_ Male' 'native_country_ Cambodia'\n",
      " 'native_country_ Canada' 'native_country_ China'\n",
      " 'native_country_ Columbia' 'native_country_ Cuba'\n",
      " 'native_country_ Dominican-Republic' 'native_country_ Ecuador'\n",
      " 'native_country_ El-Salvador' 'native_country_ England'\n",
      " 'native_country_ France' 'native_country_ Germany'\n",
      " 'native_country_ Greece' 'native_country_ Guatemala'\n",
      " 'native_country_ Haiti' 'native_country_ Holand-Netherlands'\n",
      " 'native_country_ Honduras' 'native_country_ Hong'\n",
      " 'native_country_ Hungary' 'native_country_ India' 'native_country_ Iran'\n",
      " 'native_country_ Ireland' 'native_country_ Italy'\n",
      " 'native_country_ Jamaica' 'native_country_ Japan' 'native_country_ Laos'\n",
      " 'native_country_ Mexico' 'native_country_ Nicaragua'\n",
      " 'native_country_ Outlying-US(Guam-USVI-etc)' 'native_country_ Peru'\n",
      " 'native_country_ Philippines' 'native_country_ Poland'\n",
      " 'native_country_ Portugal' 'native_country_ Puerto-Rico'\n",
      " 'native_country_ Scotland' 'native_country_ South'\n",
      " 'native_country_ Taiwan' 'native_country_ Thailand'\n",
      " 'native_country_ Trinadad&Tobago' 'native_country_ United-States'\n",
      " 'native_country_ Vietnam' 'native_country_ Yugoslavia']\n"
     ]
    }
   ],
   "source": [
    "print(income_ohe.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'workclass' 'fnlwgt' 'education' 'education_num' 'marital_status'\n",
      " 'occupation' 'relationship' 'race' 'sex' 'capital_gain' 'capital_loss'\n",
      " 'hourspw' 'native_country' 'income']\n"
     ]
    }
   ],
   "source": [
    "print(income.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = income_ohe\n",
    "y = income['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 104)\n",
      "(30162,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22621, 104)\n",
      "(7541, 104)\n",
      "(22621,)\n",
      "(7541,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <=50K    17015\n",
      " >50K      5606\n",
      "Name: income, dtype: int64\n",
      " <=50K    5639\n",
      " >50K     1902\n",
      "Name: income, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# examine the class distribution of the testing set (using a Pandas Series method)\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Logistic Regression\": LogisticRegression()  \n",
    "\"Nearest Neighbors\": KNeighborsClassifier()  \n",
    "\"Linear SVM\": SVC()  \n",
    "\"Gradient Boosting Classifier\": GradientBoostingClassifier()  \n",
    "\"Decision Tree\": tree.DecisionTreeClassifier()  \n",
    "\"Random Forest\": RandomForestClassifier(n_estimators = 18)  \n",
    "\"Neural Net\": MLPClassifier(alpha = 1)  \n",
    "\"Naive Bayes\": GaussianNB()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784776554834\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: [' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K'\n",
      " ' >50K' ' >50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' >50K'\n",
      " ' <=50K' ' <=50K' ' <=50K' ' >50K' ' <=50K' ' <=50K' ' <=50K' ' >50K'\n",
      " ' <=50K']\n",
      "Pred: [' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K'\n",
      " ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' >50K' ' <=50K' ' >50K'\n",
      " ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K' ' <=50K'\n",
      " ' <=50K']\n"
     ]
    }
   ],
   "source": [
    "# print the first 25 true and predicted responses\n",
    "print('True:', y_test.values[0:25])\n",
    "print('Pred:', y_pred_class[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5431  208]\n",
      " [1415  487]]\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted values\n",
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score\n",
    "\n",
    "def Evaluate(predicted, actual, labels):\n",
    "    output_labels = []\n",
    "    output = []\n",
    "    \n",
    "    # Calculate and display confusion matrix\n",
    "    cm = confusion_matrix(actual, predicted, labels=labels)\n",
    "    print('Confusion matrix\\n- x-axis is true labels \\n- y-axis is predicted labels')\n",
    "    print(cm)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    accuracy = np.array([float(np.trace(cm)) / np.sum(cm)] * len(labels))\n",
    "    precision = precision_score(actual, predicted, average=None, labels=labels)\n",
    "    recall = recall_score(actual, predicted, average=None, labels=labels)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    output.extend([accuracy.tolist(), precision.tolist(), recall.tolist(), f1.tolist()])\n",
    "    output_labels.extend(['accuracy', 'precision', 'recall', 'F1'])\n",
    "    \n",
    "    # Calculate the macro versions of these metrics\n",
    "    output.extend([[np.mean(precision)] * len(labels),\n",
    "                   [np.mean(recall)] * len(labels),\n",
    "                   [np.mean(f1)] * len(labels)])\n",
    "    output_labels.extend(['macro precision', 'macro recall', 'macro F1'])\n",
    "    \n",
    "    # Find the one-vs.-all confusion matrix\n",
    "    cm_row_sums = cm.sum(axis = 1)\n",
    "    cm_col_sums = cm.sum(axis = 0)\n",
    "    s = np.zeros((2, 2))\n",
    "    for i in range(len(labels)):\n",
    "        v = np.array([[cm[i, i],\n",
    "                       cm_row_sums[i] - cm[i, i]],\n",
    "                      [cm_col_sums[i] - cm[i, i],\n",
    "                       np.sum(cm) + cm[i, i] - (cm_row_sums[i] + cm_col_sums[i])]])\n",
    "        s += v\n",
    "    s_row_sums = s.sum(axis = 1)\n",
    "    \n",
    "    # Add average accuracy and micro-averaged  precision/recall/F1\n",
    "    avg_accuracy = [np.trace(s) / np.sum(s)] * len(labels)\n",
    "    micro_prf = [float(s[0,0]) / s_row_sums[0]] * len(labels)\n",
    "    output.extend([avg_accuracy, micro_prf])\n",
    "    output_labels.extend(['average accuracy',\n",
    "                          'micro-averaged precision/recall/F1'])\n",
    "    \n",
    "    # Compute metrics for the majority classifier\n",
    "    mc_index = np.where(cm_row_sums == np.max(cm_row_sums))[0][0]\n",
    "    cm_row_dist = cm_row_sums / float(np.sum(cm))\n",
    "    mc_accuracy = 0 * cm_row_dist; mc_accuracy[mc_index] = cm_row_dist[mc_index]\n",
    "    mc_recall = 0 * cm_row_dist; mc_recall[mc_index] = 1\n",
    "    mc_precision = 0 * cm_row_dist\n",
    "    mc_precision[mc_index] = cm_row_dist[mc_index]\n",
    "    mc_F1 = 0 * cm_row_dist;\n",
    "    mc_F1[mc_index] = 2 * mc_precision[mc_index] / (mc_precision[mc_index] + 1)\n",
    "    output.extend([mc_accuracy.tolist(), mc_recall.tolist(),\n",
    "                   mc_precision.tolist(), mc_F1.tolist()])\n",
    "    output_labels.extend(['majority class accuracy', 'majority class recall',\n",
    "                          'majority class precision', 'majority class F1'])\n",
    "        \n",
    "    # Random accuracy and kappa\n",
    "    cm_col_dist = cm_col_sums / float(np.sum(cm))\n",
    "    exp_accuracy = np.array([np.sum(cm_row_dist * cm_col_dist)] * len(labels))\n",
    "    kappa = (accuracy - exp_accuracy) / (1 - exp_accuracy)\n",
    "    output.extend([exp_accuracy.tolist(), kappa.tolist()])\n",
    "    output_labels.extend(['expected accuracy', 'kappa'])\n",
    "    \n",
    "\n",
    "    # Random guess\n",
    "    rg_accuracy = np.ones(len(labels)) / float(len(labels))\n",
    "    rg_precision = cm_row_dist\n",
    "    rg_recall = np.ones(len(labels)) / float(len(labels))\n",
    "    rg_F1 = 2 * cm_row_dist / (len(labels) * cm_row_dist + 1)\n",
    "    output.extend([rg_accuracy.tolist(), rg_precision.tolist(),\n",
    "                   rg_recall.tolist(), rg_F1.tolist()])\n",
    "    output_labels.extend(['random guess accuracy', 'random guess precision',\n",
    "                          'random guess recall', 'random guess F1'])\n",
    "    \n",
    "    # Random weighted guess\n",
    "    rwg_accuracy = np.ones(len(labels)) * sum(cm_row_dist**2)\n",
    "    rwg_precision = cm_row_dist\n",
    "    rwg_recall = cm_row_dist\n",
    "    rwg_F1 = cm_row_dist\n",
    "    output.extend([rwg_accuracy.tolist(), rwg_precision.tolist(),\n",
    "                   rwg_recall.tolist(), rwg_F1.tolist()])\n",
    "    output_labels.extend(['random weighted guess accuracy',\n",
    "                          'random weighted guess precision',\n",
    "                          'random weighted guess recall',\n",
    "                          'random weighted guess F1'])\n",
    "\n",
    "    output_df = pd.DataFrame(output, columns=labels)\n",
    "    output_df.index = output_labels\n",
    "                  \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "- x-axis is true labels \n",
      "- y-axis is predicted labels\n",
      "[[5431  208]\n",
      " [1415  487]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluation_result = Evaluate(actual = y_test.values,\n",
    "                                 predicted = y_pred_class,\n",
    "                                 labels = [' <=50K', ' >50K'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;=50K</th>\n",
       "      <th>&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.784777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.793310</td>\n",
       "      <td>0.700719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.963114</td>\n",
       "      <td>0.256046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.870004</td>\n",
       "      <td>0.375048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.747015</td>\n",
       "      <td>0.747015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.609580</td>\n",
       "      <td>0.609580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro F1</th>\n",
       "      <td>0.622526</td>\n",
       "      <td>0.622526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average accuracy</th>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.784777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro-averaged precision/recall/F1</th>\n",
       "      <td>0.784777</td>\n",
       "      <td>0.784777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority class accuracy</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority class recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority class precision</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority class F1</th>\n",
       "      <td>0.855690</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected accuracy</th>\n",
       "      <td>0.702107</td>\n",
       "      <td>0.702107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kappa</th>\n",
       "      <td>0.277515</td>\n",
       "      <td>0.277515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random guess accuracy</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random guess precision</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.252221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random guess recall</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random guess F1</th>\n",
       "      <td>0.599288</td>\n",
       "      <td>0.335302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random weighted guess accuracy</th>\n",
       "      <td>0.622789</td>\n",
       "      <td>0.622789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random weighted guess precision</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.252221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random weighted guess recall</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.252221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random weighted guess F1</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.252221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       <=50K      >50K\n",
       "accuracy                            0.784777  0.784777\n",
       "precision                           0.793310  0.700719\n",
       "recall                              0.963114  0.256046\n",
       "F1                                  0.870004  0.375048\n",
       "macro precision                     0.747015  0.747015\n",
       "macro recall                        0.609580  0.609580\n",
       "macro F1                            0.622526  0.622526\n",
       "average accuracy                    0.784777  0.784777\n",
       "micro-averaged precision/recall/F1  0.784777  0.784777\n",
       "majority class accuracy             0.747779  0.000000\n",
       "majority class recall               1.000000  0.000000\n",
       "majority class precision            0.747779  0.000000\n",
       "majority class F1                   0.855690  0.000000\n",
       "expected accuracy                   0.702107  0.702107\n",
       "kappa                               0.277515  0.277515\n",
       "random guess accuracy               0.500000  0.500000\n",
       "random guess precision              0.747779  0.252221\n",
       "random guess recall                 0.500000  0.500000\n",
       "random guess F1                     0.599288  0.335302\n",
       "random weighted guess accuracy      0.622789  0.622789\n",
       "random weighted guess precision     0.747779  0.252221\n",
       "random weighted guess recall        0.747779  0.252221\n",
       "random weighted guess F1            0.747779  0.252221"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For datasets, where this is not the case we can play around with the features in the dataset, add extra features from additional datasets or change the parameters of the classifiers in order to improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Required Python Packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Fit the model\n",
    "\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7541,)\n",
      "(7541,)\n"
     ]
    }
   ],
   "source": [
    "predictions = rfc.predict(X_test)\n",
    "    \n",
    "print(predictions.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "- x-axis is true labels \n",
      "- y-axis is predicted labels\n",
      "[[5207  432]\n",
      " [ 798 1104]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;=50K</th>\n",
       "      <th>&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.836892</td>\n",
       "      <td>0.836892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.867111</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.923391</td>\n",
       "      <td>0.580442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.894366</td>\n",
       "      <td>0.642234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro precision</th>\n",
       "      <td>0.792930</td>\n",
       "      <td>0.792930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro recall</th>\n",
       "      <td>0.751916</td>\n",
       "      <td>0.751916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro F1</th>\n",
       "      <td>0.768300</td>\n",
       "      <td>0.768300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average accuracy</th>\n",
       "      <td>0.836892</td>\n",
       "      <td>0.836892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro-averaged precision/recall/F1</th>\n",
       "      <td>0.836892</td>\n",
       "      <td>0.836892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority class accuracy</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority class recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority class precision</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority class F1</th>\n",
       "      <td>0.855690</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected accuracy</th>\n",
       "      <td>0.646840</td>\n",
       "      <td>0.646840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kappa</th>\n",
       "      <td>0.538146</td>\n",
       "      <td>0.538146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random guess accuracy</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random guess precision</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.252221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random guess recall</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random guess F1</th>\n",
       "      <td>0.599288</td>\n",
       "      <td>0.335302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random weighted guess accuracy</th>\n",
       "      <td>0.622789</td>\n",
       "      <td>0.622789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random weighted guess precision</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.252221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random weighted guess recall</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.252221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random weighted guess F1</th>\n",
       "      <td>0.747779</td>\n",
       "      <td>0.252221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       <=50K      >50K\n",
       "accuracy                            0.836892  0.836892\n",
       "precision                           0.867111  0.718750\n",
       "recall                              0.923391  0.580442\n",
       "F1                                  0.894366  0.642234\n",
       "macro precision                     0.792930  0.792930\n",
       "macro recall                        0.751916  0.751916\n",
       "macro F1                            0.768300  0.768300\n",
       "average accuracy                    0.836892  0.836892\n",
       "micro-averaged precision/recall/F1  0.836892  0.836892\n",
       "majority class accuracy             0.747779  0.000000\n",
       "majority class recall               1.000000  0.000000\n",
       "majority class precision            0.747779  0.000000\n",
       "majority class F1                   0.855690  0.000000\n",
       "expected accuracy                   0.646840  0.646840\n",
       "kappa                               0.538146  0.538146\n",
       "random guess accuracy               0.500000  0.500000\n",
       "random guess precision              0.747779  0.252221\n",
       "random guess recall                 0.500000  0.500000\n",
       "random guess F1                     0.599288  0.335302\n",
       "random weighted guess accuracy      0.622789  0.622789\n",
       "random weighted guess precision     0.747779  0.252221\n",
       "random weighted guess recall        0.747779  0.252221\n",
       "random weighted guess F1            0.747779  0.252221"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_result = Evaluate(actual = y_test.values,\n",
    "                                 predicted = predictions,\n",
    "                                 labels = [' <=50K', ' >50K'])\n",
    "evaluation_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
