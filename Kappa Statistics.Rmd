---
title: "Is your Classification Model making lucky guesses (Part 3)"
author: "Shaheen"
date: "Monday, March 01, 2016"
output: html_document
---

### Kappa Statistics  
Author: Shaheen Gauher

Kappa Statistic compares the accuracy of the machine learning classifier to the accuracy we would expect to achieve purely by chance. We will call the accuracy achieved by chance, the Expected Accuracy. If the machine learning classifier yields a total accuracy of 85% when the Expected Accuracy was 80%, it is not as great as when the Expected Accuracy is say 40%. To compute Expected accuracy, we first compute the expected frequency of agreements by chance between prediction and actual for each class. The sum of the expected frequencies of agreement by chance for each class gives the Expected Accuracy. The Expected Accuracy is then used to compute Kappa as

Kappa = (Total Accuracy - Expected Accuracy) / (1 - Expected Accuracy)

In the example below I will use iris data set to build a classification model using Decision Forest. Then I will compare the accuracy and Kappa for the model. The iris data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.

Note: The code below requires MRS (Microsoft R Server, formally Revolution R Enterprise (RRE))  
http://blog.revolutionanalytics.com/2016/01/microsoft-r-open.html    
MRS can be downloaded from https://www.dreamspark.com/Product/Product.aspx?productid=105



```{r}
#download data from
#https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
datad_iris=read.table("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data", 
                        header=F,sep=",",na.strings="NA")  #150 rows and 5 columns for iris data
class(datad_iris)  #"data.frame"
#convert data frame to xdf object using rxDataStep() 
pathc=getwd()
iris_xdf =file.path(pathc,'iris_xdf.xdf') 
data_iris = rxDataStep(inData = datad_iris, outFile = iris_xdf ,
                  rowsPerRead=50, overwrite=TRUE)
class(data_iris)  # "RxXdfData"

#rename the label col 'V5' as 'LabelsCol'
names(data_iris)[names(data_iris)=='V5'] = 'LabelsCol'


#*** Split the data into training and testing data. ***

#use rxDataStep() to create a col called 'splitcol' to use for splitting
rxDataStep(inData=data_iris,outFile=data_iris,transforms=list(splitcol=factor(rbinom(.rxNumRows,1,0.8),labels=c('test','train'))),overwrite=T)  

#split using the col "splitcol" 
#rxSplit() -- Splits an input '.xdf' file or data frame into multiple '.xdf' files or a list of data frames.
listofxdfs = rxSplit(data_iris,outFileBase='irissplit',outFileSuffixes=c("Train", "Test"),
                       splitByFactor = "splitcol",overwrite=T )

trainingdata = listofxdfs[[2]]
testdata = listofxdfs[[1]]

#Build Machine Learning model - Decision Forest rxDForest()

#collect names of columns (features) to be used for modelling
allfeatures = setdiff(names(data_iris),c('LabelsCol','splitcol'))

#create formula for modelling
formula = as.formula(paste('LabelsCol',paste(allfeatures,collapse=' + '),sep=' ~ '))  
formula

#using rxDForest() to build ML model
DForest_model <- rxDForest(formula , data = trainingdata, seed = 10, cp = 0.01, nTree = 50, mTry = 2,                   
                    overwrite = TRUE, reportProgress = 0)
class(DForest_model) #"rxDForest" 
ML_model = DForest_model
ML_model

#Compute the accuracy of the model and compare to Kappa for the model
train_modelout = rxPredict(ML_model, data = trainingdata, outData = 'temp.xdf', overwrite = TRUE, writeModelVars = TRUE, predVarNames = "PredictedLabels",type='class')
class(train_modelout) #"RxXdfData"


mytemp_xdf=RxXdfData("mytemp_xdf.xdf") #initialise an xdf object 
results_model = rxDataStep(inData = train_modelout, outFile = mytemp_xdf,varsToKeep = c('PredictedLabels','LabelsCol'),overwrite = TRUE )
dim(results_model)


cmatrix = rxCrossTabs(~PredictedLabels:LabelsCol,results_model,returnXtabs = T)
class(cmatrix) #"xtabs" "table"

#Compute accuracy of the model
accuracy = sum(diag(cmatrix)) / sum(cmatrix)
cat('accuracy=',accuracy,'\n')

#Compute Kappa
#get marginal frequency for each class
Marg_freq_class = function(i){rowSums(cmatrix)[i] * colSums(cmatrix)[i] / sum(cmatrix) }
n = sum(cmatrix)  #total number of instances
accuracy_exp = sum(sapply(1:3,FUN=function(x){sum(Marg_freq_class(x))}))/n
cat('Expected Accuracy=',accuracy_exp)

kappa = (accuracy - accuracy_exp) / (1 - accuracy_exp)
cat('kappa=',kappa,'\n')

#remove file
if(file.exists("iris_xdf.xdf") ) {  file.remove("iris_xdf.xdf") }
```

